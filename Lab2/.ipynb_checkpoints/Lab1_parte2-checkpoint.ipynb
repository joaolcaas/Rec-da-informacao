{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>João Lucas Araújo</h1> \n",
    "<h1>Campina grande, UFCG</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this lab, we going to analise a data that have a lot of news.\n",
    "Using thecniques that we saw on the classes, our mission is return the best 5 documents each metric (binary,tf,tf-idf and BM25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Librarys</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk as nltk\n",
    "import operator as operator\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>str_busca</th>\n",
       "      <th>google</th>\n",
       "      <th>busca_binaria</th>\n",
       "      <th>tf</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>bm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>segundo turno</td>\n",
       "      <td>[1062, 1942, 2161, 2078, 2073]</td>\n",
       "      <td>[2048, 1, 2049, 2050, 4096]</td>\n",
       "      <td>[2744, 7, 2112, 7672, 2388]</td>\n",
       "      <td>[2744, 2112, 7672, 1235, 2388]</td>\n",
       "      <td>[2744, 2112, 7672, 2388, 2178]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lava jato</td>\n",
       "      <td>[616, 164, 1734, 163, 6716]</td>\n",
       "      <td>[3, 13, 15, 27, 6177]</td>\n",
       "      <td>[163, 353, 2807, 127, 359]</td>\n",
       "      <td>[163, 353, 2807, 127, 359]</td>\n",
       "      <td>[163, 353, 2807, 127, 359]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>projeto de lei</td>\n",
       "      <td>[2853, 275, 978, 7092, 3171]</td>\n",
       "      <td>[3584, 6145, 8194, 8706, 6660]</td>\n",
       "      <td>[7, 3942, 7017, 1250, 6942]</td>\n",
       "      <td>[2232, 6461, 2853, 3171, 3942]</td>\n",
       "      <td>[2232, 6461, 3171, 2853, 3170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compra de voto</td>\n",
       "      <td>[2200, 8615, 2265, 7746, 82]</td>\n",
       "      <td>[7424, 2178, 6531, 5122, 2311]</td>\n",
       "      <td>[3942, 7017, 5129, 2047, 748]</td>\n",
       "      <td>[7343, 7293, 6791, 3942, 2047]</td>\n",
       "      <td>[7343, 7293, 6791, 7329, 8615]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ministério público</td>\n",
       "      <td>[64, 6652, 164, 6550, 8615]</td>\n",
       "      <td>[8194, 7, 4104, 8201, 4109]</td>\n",
       "      <td>[6798, 8018, 6244, 6965, 6550]</td>\n",
       "      <td>[6798, 8018, 6244, 6965, 6550]</td>\n",
       "      <td>[6798, 8018, 6244, 6965, 6550]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            str_busca                          google  \\\n",
       "0       segundo turno  [1062, 1942, 2161, 2078, 2073]   \n",
       "1           lava jato     [616, 164, 1734, 163, 6716]   \n",
       "2      projeto de lei    [2853, 275, 978, 7092, 3171]   \n",
       "3      compra de voto    [2200, 8615, 2265, 7746, 82]   \n",
       "4  ministério público     [64, 6652, 164, 6550, 8615]   \n",
       "\n",
       "                    busca_binaria                              tf  \\\n",
       "0     [2048, 1, 2049, 2050, 4096]     [2744, 7, 2112, 7672, 2388]   \n",
       "1           [3, 13, 15, 27, 6177]      [163, 353, 2807, 127, 359]   \n",
       "2  [3584, 6145, 8194, 8706, 6660]     [7, 3942, 7017, 1250, 6942]   \n",
       "3  [7424, 2178, 6531, 5122, 2311]   [3942, 7017, 5129, 2047, 748]   \n",
       "4     [8194, 7, 4104, 8201, 4109]  [6798, 8018, 6244, 6965, 6550]   \n",
       "\n",
       "                            tfidf                            bm25  \n",
       "0  [2744, 2112, 7672, 1235, 2388]  [2744, 2112, 7672, 2388, 2178]  \n",
       "1      [163, 353, 2807, 127, 359]      [163, 353, 2807, 127, 359]  \n",
       "2  [2232, 6461, 2853, 3171, 3942]  [2232, 6461, 3171, 2853, 3170]  \n",
       "3  [7343, 7293, 6791, 3942, 2047]  [7343, 7293, 6791, 7329, 8615]  \n",
       "4  [6798, 8018, 6244, 6965, 6550]  [6798, 8018, 6244, 6965, 6550]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Data/estadao_noticias_eleicao.csv\")\n",
    "gabarito = pd.read_csv(\"./Gabarito/gabarito.csv\")\n",
    "gabarito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Number of documents on data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filtering NA's</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>titulo</th>\n",
       "      <th>subTitulo</th>\n",
       "      <th>conteudo</th>\n",
       "      <th>url</th>\n",
       "      <th>idNoticia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>PT espera 30 mil pessoas em festa na Esplanada</td>\n",
       "      <td>Objetivo é demonstrar apoio popular a Dilma e ...</td>\n",
       "      <td>BRASÍLIA - Após o desgaste provocado com o lan...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>Alckmin toma posse de olho no Planalto</td>\n",
       "      <td>Governador reeleito tenta amarrar tucanos paul...</td>\n",
       "      <td>Reeleito em outubro, o governador tucano Geral...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>Seis obstáculos e desafios do segundo mandato ...</td>\n",
       "      <td>Em meio a escândalo de corrupção, presidente t...</td>\n",
       "      <td>1. Rearranjo das contas A nova equipe econôm...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td></td>\n",
       "      <td>Veja as principais fotos do dia e dos eventos ...</td>\n",
       "      <td></td>\n",
       "      <td>http://fotos.estadao.com.br/fotos/politica,dil...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td></td>\n",
       "      <td>Veja as principais fotos do dia e dos eventos ...</td>\n",
       "      <td></td>\n",
       "      <td>http://fotos.estadao.com.br/fotos/politica,dil...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp                                             titulo  \\\n",
       "0  2014-12-31T00:00:00Z     PT espera 30 mil pessoas em festa na Esplanada   \n",
       "1  2014-12-31T00:00:00Z             Alckmin toma posse de olho no Planalto   \n",
       "2  2014-12-31T00:00:00Z  Seis obstáculos e desafios do segundo mandato ...   \n",
       "3  2014-12-31T00:00:00Z                                                      \n",
       "4  2014-12-31T00:00:00Z                                                      \n",
       "\n",
       "                                           subTitulo  \\\n",
       "0  Objetivo é demonstrar apoio popular a Dilma e ...   \n",
       "1  Governador reeleito tenta amarrar tucanos paul...   \n",
       "2  Em meio a escândalo de corrupção, presidente t...   \n",
       "3  Veja as principais fotos do dia e dos eventos ...   \n",
       "4  Veja as principais fotos do dia e dos eventos ...   \n",
       "\n",
       "                                            conteudo  \\\n",
       "0  BRASÍLIA - Após o desgaste provocado com o lan...   \n",
       "1  Reeleito em outubro, o governador tucano Geral...   \n",
       "2    1. Rearranjo das contas A nova equipe econôm...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                                 url  idNoticia  \n",
       "0  http://politica.estadao.com.br/noticias/geral,...          1  \n",
       "1  http://politica.estadao.com.br/noticias/geral,...          2  \n",
       "2  http://politica.estadao.com.br/noticias/geral,...          3  \n",
       "3  http://fotos.estadao.com.br/fotos/politica,dil...          4  \n",
       "4  http://fotos.estadao.com.br/fotos/politica,dil...          5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna('')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dictonary where we going to save our searchs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_palavras = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(first_tuple,second_tuple,type_merge):\n",
    "    \"\"\"\n",
    "    function that will merge two tuples, depending on type\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    first_tuple: Tuple \n",
    "        first tuple we want to merge\n",
    "    second_tuple: Tuple \n",
    "        second tuple we want to merge\n",
    "    type_merge: String\n",
    "        it will decide the type of the merge we want\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    merge_tuple: Tuple\n",
    "        return the merge between first_tuple and second_tuple\n",
    "    \n",
    "    \"\"\"  \n",
    "    merged_tuple = []\n",
    "    \n",
    "    for y in range(num_docs):\n",
    "        if(first_tuple[y][1] != 0 and second_tuple[y][0] != 0):\n",
    "            if(type_merge == 'tf'):\n",
    "                merged_tuple.append((first_tuple[y][0],first_tuple[y][1] + second_tuple[y][1]))\n",
    "            elif(type_merge == 'binary'):\n",
    "                 merged_tuple.append((first_tuple[y][0],first_tuple[y][2] + second_tuple[y][2]))\n",
    "                 \n",
    "            elif(type_merge == 'tfidf'):\n",
    "                merged_tuple.append((first_tuple[y][0],((first_tuple[y][1]*first_tuple[y][3]) + (second_tuple[y][1]*second_tuple[y][3]))))\n",
    "                \n",
    "            elif(type_merge == 'bm25'):\n",
    "                k = 5\n",
    "                merged_tuple.append((first_tuple[y][0],calc_bm25(first_tuple[y][1]) + calc_bm25(second_tuple[y][1])))\n",
    "                \n",
    "    return merged_tuple\n",
    "\n",
    "def calc_bm25(tf):\n",
    "    \"\"\"\n",
    "    function that will calculated a bm25 term from a received term frequency\n",
    "    \n",
    "    Args \n",
    "    ---------\n",
    "    tf: int\n",
    "        term frequency coming from the word\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    calc_final: int\n",
    "        bm25 term\n",
    "    \"\"\"\n",
    "    k = 5\n",
    "    calc_final = ((k+1)*tf)/(tf+k)\n",
    "    return calc_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(searched_word):\n",
    "    \"\"\"\n",
    "    function that will search for words equals \"searched_word\" in documents\n",
    "    \n",
    "    Args\n",
    "    ---------\n",
    "    searched_word: String\n",
    "        unique word that gonna be searched in documents\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    dict_palavras[searched_word]: Array\n",
    "            return an array with all documents,frequency of occurrence and a binary term (that says \n",
    "            if the world is in that document or not) about that searched_word by document\n",
    "    \n",
    "    \"\"\"\n",
    "    if(searched_word in dict_palavras):\n",
    "        return dict_palavras[searched_word]\n",
    "    else:\n",
    "        dict_palavras[searched_word] = []\n",
    "        idf_word = calculate_frequency_idf(searched_word)\n",
    "        for i in range(num_docs):\n",
    "            tf = 0\n",
    "            titulo = data.loc[i,'titulo']\n",
    "            sub_titulo = data.loc[i,'subTitulo']\n",
    "            conteudo = data.loc[i,'conteudo']\n",
    "            new_world = titulo + \" \" + sub_titulo + \" \" + conteudo\n",
    "            new_world_nova = nltk.word_tokenize(new_world.lower())\n",
    "            for palavra in new_world_nova:\n",
    "                if(palavra == searched_word):\n",
    "                    tf = tf + 1\n",
    "            if(tf > 0):\n",
    "                dict_palavras[searched_word].append((data.loc[i,'idNoticia'],tf,1,idf_word))\n",
    "            else:\n",
    "                dict_palavras[searched_word].append((data.loc[i,'idNoticia'],tf,0,idf_word))\n",
    "    return dict_palavras[searched_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency_idf(searched_word):\n",
    "    \"\"\"\n",
    "    Function that will recive a word and search for it to know in how many documents this word appears. In the end,\n",
    "    we want to know the idf of this word\n",
    "    \n",
    "    Args\n",
    "    ---------\n",
    "    searched_word: String\n",
    "        word that will be searched on data\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    idf_final: int\n",
    "        return the word's idf\n",
    "    \"\"\"\n",
    "    idf = 0\n",
    "    for i in range(num_docs):\n",
    "        titulo = data.loc[i,'titulo']\n",
    "        sub_titulo = data.loc[i,'subTitulo']\n",
    "        conteudo = data.loc[i,'conteudo']\n",
    "        new_world = titulo + \" \" + sub_titulo + \" \" + conteudo\n",
    "        new_world_nova = nltk.word_tokenize(new_world.lower())\n",
    "        for palavra in new_world_nova:\n",
    "            if(palavra == searched_word):\n",
    "                idf = idf + 1\n",
    "                break\n",
    "                \n",
    "    idf_final = calculate_idf_log(idf)\n",
    "    return idf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_idf_log(appears_on_doc):\n",
    "    \"\"\"\n",
    "    Function that will return the idf from the received frequency\n",
    "    \n",
    "    Args\n",
    "    ---------\n",
    "    appears_on_doc: int\n",
    "        number of times certain word appears on the data\n",
    "    Returns\n",
    "    ---------\n",
    "    idf: int\n",
    "        result of idf from appears_on_doc\n",
    "    \"\"\"\n",
    "    idf = math.log((num_docs + 1)/appears_on_doc)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Binary</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On binary model, we have the idea of adding on dictonary just values 0 or 1, witch this values will say if the word is or is not on the dictionary. The maximum points of this model it is the size of the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplest_vsm(query):\n",
    "    '''\n",
    "    function that will search for query's words in documents and return a array of\n",
    "    tuple sorted by the binary metrics about these words\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "       this query come from the user and will serve for do the search, looking for these words on the documents\n",
    "   \n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    final_resut: Array\n",
    "        this array contain a sorted documents by the binary metrics of these query's words\n",
    "    \n",
    "    '''\n",
    "\n",
    "    query_splited = nltk.word_tokenize(query)\n",
    "    i = 0\n",
    "    while(i < len(query_splited )-1):\n",
    "        final_result = merge(search_query(query_splited[i]),search_query(query_splited[i+1]),'binary')\n",
    "        i+=1\n",
    "    final_result.sort(key = operator.itemgetter(1),reverse = True)\n",
    "    return final_result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Term Frequency</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On binary model, we note that exist a lot of draw. To stop it, we have to put some weight to see the difference between the words.\n",
    "\n",
    "On Term Frequency model, we gonna looking for the number of times which word appears on the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_vsm(query):\n",
    "    \"\"\"\n",
    "    function that will search for query's words in documents and return a array of \n",
    "    \n",
    "    tuple sorted by the frequency about these words\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    query: String\n",
    "        this query come from the user and will serve for do the search, looking for these words on the documents\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    final_resut: Array\n",
    "        this array contain a sorted documents by the frequency of these query's words\n",
    "    \n",
    "    \"\"\"\n",
    "    query_splited = nltk.word_tokenize(query)\n",
    "    i = 0\n",
    "    while(i < len(query_splited )-1):\n",
    "        final_result = merge(search_query(query_splited[i]),search_query(query_splited[i+1]),'tf')    \n",
    "        i+=1\n",
    "    \n",
    "\n",
    "    final_result.sort(key = operator.itemgetter(1),reverse = True)\n",
    "    return final_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TF-IDF</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the frequency metrics, we had note that result was different, however was not so efficient, in view of the word can appears a lot of times and have no importance.\n",
    "\n",
    "On TF-IDF model, we can give weight to words, that is, the words little importance for the search will have their values decreased to return a better search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_vsm(query):\n",
    "    \"\"\"\n",
    "    function that will search for query's words in documents and return a array of \n",
    "    \n",
    "    tuple sorted by the tf-df about these words\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    query: String\n",
    "        this query come from the user and will serve for do the search, looking for these words on the documents\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    final_resut: Array\n",
    "        this array contain a sorted documents by the frequency of these query's words\n",
    "    \"\"\"\n",
    "    query_splited = nltk.word_tokenize(query)\n",
    "    i = 0\n",
    "    while(i < len(query_splited )-1):\n",
    "        final_result = merge(search_query(query_splited[i]),search_query(query_splited[i+1]),'tfidf')\n",
    "        i+=1\n",
    "    final_result.sort(key = operator.itemgetter(1),reverse = True)\n",
    "    return final_result\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>BM 25</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other metric which we can ordered these documents it's BM25, where this metric takes into consideration the frequency on each document and a K that will determine the importance's degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm_25(query):\n",
    "    \"\"\"\n",
    "    function that will search for query's words in documents and return a array of \n",
    "    \n",
    "    tuple sorted by the bm25 about these words\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    query: String\n",
    "        this query come from the user and will serve for do the search, looking for these words on the documents\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    final_resut: Array\n",
    "        this array contain a sorted documents by the frequency of these query's words\n",
    "    \n",
    "    \"\"\"\n",
    "    query_splited = nltk.word_tokenize(query)\n",
    "    i = 0\n",
    "    while(i < len(query_splited )-1):\n",
    "        final_result = merge(search_query(query_splited[i]),search_query(query_splited[i+1]),'bm25')\n",
    "        i+=1\n",
    "    final_result.sort(key = operator.itemgetter(1),reverse = True)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Verifying Precision </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_five(type_get,query):\n",
    "    \"\"\"\n",
    "    That function will return the first five elements from the search, \n",
    "    where this list it's a searched query\n",
    "    \n",
    "    Args\n",
    "    ---------\n",
    "    type_get: String\n",
    "        the type of search\n",
    "    query: String\n",
    "        the query that will be searched\n",
    "    Returns\n",
    "    ---------\n",
    "    answer: list\n",
    "        it will return the first five elements from the search\n",
    "    \"\"\"\n",
    "    answer = []\n",
    "    if(type_get == 'tf'):\n",
    "        array_query = tf_vsm(query)\n",
    "    elif(type_get == 'binary'):\n",
    "        array_query = simplest_vsm(query)\n",
    "    elif(type_get =='tfidf'):\n",
    "        array_query = idf_vsm(query)\n",
    "    elif(type_get == 'bm25'):\n",
    "        array_query = bm_25(query)\n",
    "    for i in range(5):\n",
    "        answer.append(array_query[i][0])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>BINARY TEST</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision Binary: 0.960\n",
      "precision Google: 0.929\n"
     ]
    }
   ],
   "source": [
    "binary_answer = []\n",
    "for i in range(len(gabarito.str_busca)):\n",
    "    binary_answer.append(get_first_five('binary',gabarito.str_busca[i]))\n",
    "binary_answer = list(map(str, binary_answer))\n",
    "\n",
    "print('precision Binary: %.3f'%(mapk(gabarito.busca_binaria,binary_answer, k=5)))\n",
    "print('precision Google: %.3f'%(mapk(gabarito.google,binary_answer, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TF TEST</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision TF: 0.960\n",
      "precision  Google: 0.784\n"
     ]
    }
   ],
   "source": [
    "tf_answer = []\n",
    "for i in range(len(gabarito.str_busca)):\n",
    "    tf_answer.append(get_first_five('tf',gabarito.str_busca[i]))\n",
    "tf_answer = list(map(str, tf_answer))\n",
    "print('precision TF: %.3f'%(mapk(gabarito.tf,tf_answer, k=5)))\n",
    "print('precision  Google: %.3f'%(mapk(gabarito.google,tf_answer, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TFIDF TEST</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision TF: 0.912\n",
      "precision  Google: 0.683\n"
     ]
    }
   ],
   "source": [
    "tfidf_answer = []\n",
    "for i in range(len(gabarito.str_busca)):\n",
    "    tfidf_answer.append(get_first_five('tfidf',gabarito.str_busca[i]))\n",
    "tfidf_answer = list(map(str, tfidf_answer))\n",
    "print('precision TF: %.3f'%(mapk(gabarito.tfidf,tfidf_answer, k=5)))\n",
    "print('precision  Google: %.3f'%(mapk(gabarito.google,tfidf_answer, k=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision TF: 0.870\n",
      "precision  Google: 0.726\n"
     ]
    }
   ],
   "source": [
    "bm25_answer = []\n",
    "for i in range(len(gabarito.str_busca)):\n",
    "    bm25_answer.append(get_first_five('bm25',gabarito.str_busca[i]))\n",
    "bm25_answer = list(map(str, bm25_answer))\n",
    "print('precision TF: %.3f'%(mapk(gabarito.bm25,bm25_answer, k=5)))\n",
    "print('precision  Google: %.3f'%(mapk(gabarito.google,bm25_answer, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, our researches did well if we compare with the feedback,however, two gained more visibility. Binary search and TF search was where the precisions showed biggest than others, both in feedback and google's feedback"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
