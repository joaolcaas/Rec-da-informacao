{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>João Lucas Araújo</h1> \n",
    "<h1>Campina grande, UFCG</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this lab, we going to analise a data that have a lot of news.\n",
    "Using thecniques that we saw on the classes, our mission is return the best 5 documents each metric (binary,tf,tf-idf and BM25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Librarys</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk as nltk\n",
    "import operator as operator\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data/estadao_noticias_eleicao.csv\")\n",
    "gabarito = pd.read_csv(\"./Gabarito/gabarito.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Number of documents on data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filtering NA's</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>titulo</th>\n",
       "      <th>subTitulo</th>\n",
       "      <th>conteudo</th>\n",
       "      <th>url</th>\n",
       "      <th>idNoticia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>PT espera 30 mil pessoas em festa na Esplanada</td>\n",
       "      <td>Objetivo é demonstrar apoio popular a Dilma e ...</td>\n",
       "      <td>BRASÍLIA - Após o desgaste provocado com o lan...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>Alckmin toma posse de olho no Planalto</td>\n",
       "      <td>Governador reeleito tenta amarrar tucanos paul...</td>\n",
       "      <td>Reeleito em outubro, o governador tucano Geral...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>Seis obstáculos e desafios do segundo mandato ...</td>\n",
       "      <td>Em meio a escândalo de corrupção, presidente t...</td>\n",
       "      <td>1. Rearranjo das contas A nova equipe econôm...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td></td>\n",
       "      <td>Veja as principais fotos do dia e dos eventos ...</td>\n",
       "      <td></td>\n",
       "      <td>http://fotos.estadao.com.br/fotos/politica,dil...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td></td>\n",
       "      <td>Veja as principais fotos do dia e dos eventos ...</td>\n",
       "      <td></td>\n",
       "      <td>http://fotos.estadao.com.br/fotos/politica,dil...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp                                             titulo  \\\n",
       "0  2014-12-31T00:00:00Z     PT espera 30 mil pessoas em festa na Esplanada   \n",
       "1  2014-12-31T00:00:00Z             Alckmin toma posse de olho no Planalto   \n",
       "2  2014-12-31T00:00:00Z  Seis obstáculos e desafios do segundo mandato ...   \n",
       "3  2014-12-31T00:00:00Z                                                      \n",
       "4  2014-12-31T00:00:00Z                                                      \n",
       "\n",
       "                                           subTitulo  \\\n",
       "0  Objetivo é demonstrar apoio popular a Dilma e ...   \n",
       "1  Governador reeleito tenta amarrar tucanos paul...   \n",
       "2  Em meio a escândalo de corrupção, presidente t...   \n",
       "3  Veja as principais fotos do dia e dos eventos ...   \n",
       "4  Veja as principais fotos do dia e dos eventos ...   \n",
       "\n",
       "                                            conteudo  \\\n",
       "0  BRASÍLIA - Após o desgaste provocado com o lan...   \n",
       "1  Reeleito em outubro, o governador tucano Geral...   \n",
       "2    1. Rearranjo das contas A nova equipe econôm...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                                 url  idNoticia  \n",
       "0  http://politica.estadao.com.br/noticias/geral,...          1  \n",
       "1  http://politica.estadao.com.br/noticias/geral,...          2  \n",
       "2  http://politica.estadao.com.br/noticias/geral,...          3  \n",
       "3  http://fotos.estadao.com.br/fotos/politica,dil...          4  \n",
       "4  http://fotos.estadao.com.br/fotos/politica,dil...          5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna('')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dictonary where we going to save our searchs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_palavras = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(first_tuple,second_tuple,type_merge):\n",
    "    \"\"\"\n",
    "    function that will merge two tuples, depending on type\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    first_tuple: Tuple \n",
    "        first tuple we want to merge\n",
    "    second_tuple: Tuple \n",
    "        second tuple we want to merge\n",
    "    type_merge: String\n",
    "        it will decide the type of the merge we want\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    merge_tuple: Tuple\n",
    "        return the merge between first_tuple and second_tuple\n",
    "    \n",
    "    \"\"\"  \n",
    "    merged_tuple = [] \n",
    "    for y in range(num_docs):\n",
    "        if(first_tuple[y][1] != 0 and second_tuple[y][0] != 0):\n",
    "            if(type_merge == 'tf'):\n",
    "                merged_tuple.append((first_tuple[y][0],first_tuple[y][1] + second_tuple[y][1]))\n",
    "            elif(type_merge == 'binary'):\n",
    "                 merged_tuple.append((first_tuple[y][0],first_tuple[y][2] + second_tuple[y][2]))\n",
    "            elif(type_merge == 'tfidf'):\n",
    "                merged_tuple.append((first_tuple[y][0],((first_tuple[y][1]*first_tuple[y][3]) + (second_tuple[y][1]*second_tuple[y][3]))))\n",
    "            elif(type_merge == 'bm25'):\n",
    "                k = 5\n",
    "                merged_tuple.append((first_tuple[y][0],calc_bm25(first_tuple[y][1]) + calc_bm25(second_tuple[y][1])))\n",
    "    return merged_tuple\n",
    "\n",
    "def calc_bm25(tf):\n",
    "    k = 5\n",
    "    return ((k+1)*tf)/(tf+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(searched_word):\n",
    "    \"\"\"\n",
    "    function that will search for words equals \"searched_word\" in documents\n",
    "    \n",
    "    Args\n",
    "    ---------\n",
    "    searched_word: String\n",
    "        unique word that gonna be searched in documents\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    dict_palavras[searched_word]: Array\n",
    "            return an array with all documents,frequency of occurrence and a binary term (that says \n",
    "            if the world is in that document or not) about that searched_word by document\n",
    "    \n",
    "    \"\"\"\n",
    "    if(searched_word in dict_palavras):\n",
    "        return dict_palavras[searched_word]\n",
    "    else:\n",
    "        dict_palavras[searched_word] = []\n",
    "        idf_word = calculate_frequency_idf(searched_word)\n",
    "        for i in range(num_docs):\n",
    "            tf = 0\n",
    "            titulo = data.loc[i,'titulo']\n",
    "            sub_titulo = data.loc[i,'subTitulo']\n",
    "            conteudo = data.loc[i,'conteudo']\n",
    "            new_world = titulo + \" \" + sub_titulo + \" \" + conteudo\n",
    "            new_world_nova = nltk.word_tokenize(new_world.lower())\n",
    "            for palavra in new_world_nova:\n",
    "                if(palavra == searched_word):\n",
    "                    tf = tf + 1\n",
    "            if(tf > 0):\n",
    "                dict_palavras[searched_word].append((data.loc[i,'idNoticia'],tf,1,idf_word))\n",
    "            else:\n",
    "                dict_palavras[searched_word].append((data.loc[i,'idNoticia'],tf,0,idf_word))\n",
    "    return dict_palavras[searched_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency_idf(searched_word):\n",
    "    \"\"\"\n",
    "    Função que vai receber uma palavra e essa palavra será pesquisada para saber em quantos documentos\n",
    "    ela aparece. Ao fim, queremos saber o idf dessa palavra.\n",
    "    \n",
    "    Args\n",
    "    ---------\n",
    "    searched_word: String\n",
    "        palavra que será procurado no data\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    idf_final: int\n",
    "        Retorna o idf da palavra\n",
    "    \"\"\"\n",
    "    idf = 0\n",
    "    for i in range(num_docs):\n",
    "        titulo = data.loc[i,'titulo']\n",
    "        sub_titulo = data.loc[i,'subTitulo']\n",
    "        conteudo = data.loc[i,'conteudo']\n",
    "        new_world = titulo + \" \" + sub_titulo + \" \" + conteudo\n",
    "        new_world_nova = nltk.word_tokenize(new_world.lower())\n",
    "        for palavra in new_world_nova:\n",
    "            if(palavra == searched_word):\n",
    "                idf = idf + 1\n",
    "                break\n",
    "                \n",
    "    idf_final = calculate_idf_log(idf)\n",
    "    return idf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_idf_log(appears_on_doc):\n",
    "    \"\"\"\n",
    "    Função que vai retornar o idf a partir da frequencia recebida\n",
    "    \n",
    "    Args\n",
    "    ---------\n",
    "    appears_on_doc: int\n",
    "        número de vezes que certa palavra aparece na data\n",
    "    Returns\n",
    "    ---------\n",
    "    idf: int\n",
    "        resultado do idf a partir do appears_on_doc\n",
    "    \"\"\"\n",
    "    idf = math.log((num_docs + 1)/appears_on_doc)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Binary</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No modelo binário, nós temos a ideia de popular o dicionário apenas com valores 0 ou 1, que vai indiciar se a palavra está ou não contida em tal documento. A pontução máxima que esse modelo vai alcançar é o tamanho da query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplest_vsm(query):\n",
    "    '''\n",
    "    function that will search for query's words in documents and return a array of\n",
    "    tuple sorted by the binary metrics about these words\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "       this query come from the user and will serve for do the search, looking for these words on the documents\n",
    "   \n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    final_resut: Array\n",
    "        this array contain a sorted documents by the binary metrics of these query's words\n",
    "    \n",
    "    '''\n",
    "\n",
    "    query_splited = nltk.word_tokenize(query)\n",
    "    i = 0\n",
    "    while(i < len(query_splited )-1):\n",
    "        final_result = merge(search_query(query_splited[i]),search_query(query_splited[i+1]),'binary')\n",
    "        i+=1\n",
    "    final_result.sort(key = operator.itemgetter(1),reverse = True)\n",
    "    return final_result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (7, 2), (13, 2), (26, 2), (69, 2)]\n"
     ]
    }
   ],
   "source": [
    "a = simplest_vsm('segundo turno')\n",
    "#TOP5\n",
    "print(a[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Term Frequency</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_vsm(query):\n",
    "    \"\"\"\n",
    "    function that will search for query's words in documents and return a array of \n",
    "    \n",
    "    tuple sorted by the frequency about these words\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    query: String\n",
    "        this query come from the user and will serve for do the search, looking for these words on the documents\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    final_resut: Array\n",
    "        this array contain a sorted documents by the frequency of these query's words\n",
    "    \n",
    "    \"\"\"\n",
    "    query_splited = nltk.word_tokenize(query)\n",
    "    i = 0\n",
    "    while(i < len(query_splited )-1):\n",
    "        final_result = merge(search_query(query_splited[i]),search_query(query_splited[i+1]),'tf')\n",
    "        i+=1\n",
    "    final_result.sort(key = operator.itemgetter(1),reverse = True)\n",
    "    return final_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2744, 43), (7, 28), (2112, 26), (7672, 26), (2388, 24)]\n"
     ]
    }
   ],
   "source": [
    "b = tf_vsm('segundo turno')\n",
    "print(b[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TF-IDF</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_vsm(query):\n",
    "    \"\"\"\n",
    "    function that will search for query's words in documents and return a array of \n",
    "    \n",
    "    tuple sorted by the tf-df about these words\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    query: String\n",
    "        this query come from the user and will serve for do the search, looking for these words on the documents\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    final_resut: Array\n",
    "        this array contain a sorted documents by the frequency of these query's words\n",
    "    \"\"\"\n",
    "    query_splited = nltk.word_tokenize(query)\n",
    "    i = 0\n",
    "    while(i < len(query_splited )-1):\n",
    "        final_result = merge(search_query(query_splited[i]),search_query(query_splited[i+1]),'tfidf')\n",
    "        i+=1\n",
    "    final_result.sort(key = operator.itemgetter(1),reverse = True)\n",
    "    return final_result\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2744, 58.309800441816776), (2112, 34.07336609451237), (7672, 34.07336609451237), (1235, 29.538524912221497), (2388, 29.41307233150485)]\n"
     ]
    }
   ],
   "source": [
    "a = idf_vsm('segundo turno')\n",
    "print(a[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(163, 50.993002870726414), (353, 50.993002870726414), (2807, 48.140562619814574), (127, 39.66122445500943), (359, 39.66122445500943)]\n"
     ]
    }
   ],
   "source": [
    "b = idf_vsm('lava jato')\n",
    "print(b[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>BM 25</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm_25(query):\n",
    "    \"\"\"\n",
    "    Função que tem o intúito de fazer uma busca nos elementos da query e retornar o\n",
    "    um array ordenado a partir da métrica bm_25\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    query: String\n",
    "        this query come from the user and will serve for do the search, looking for these words on the documents    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    fina_result: Array\n",
    "        this array contain a sorted documents by the bm25 of these query's words\n",
    "    \n",
    "    \"\"\"\n",
    "    query_splited = nltk.word_tokenize(query)\n",
    "    i = 0\n",
    "    while(i < len(query_splited )-1):\n",
    "        final_result = merge(search_query(query_splited[i]),search_query(query_splited[i+1]),'bm25')\n",
    "        i+=1\n",
    "    final_result.sort(key = operator.itemgetter(1),reverse = True)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2744, 9.695652173913043), (2112, 8.656346749226007), (7672, 8.656346749226007), (2388, 8.458333333333332), (2178, 8.25)]\n"
     ]
    }
   ],
   "source": [
    "c = bm_25('segundo turno')\n",
    "print(c[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Verifying Precision </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
