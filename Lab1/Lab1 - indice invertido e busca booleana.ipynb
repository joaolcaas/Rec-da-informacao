{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lab 1 - Indice invertido e Busca booleana<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esse primeiro lab, vamos usar os conceitos de indice invertido, que vamos será feito com o auxílio de um dicionário, e busca booleana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Para esse lab, vamos utilizar as seguintes bibliotecas:<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dados<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>conteudo</th>\n",
       "      <th>idNoticia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT espera 30 mil pessoas em festa na Esplanada</td>\n",
       "      <td>BRASÍLIA - Após o desgaste provocado com o lan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alckmin toma posse de olho no Planalto</td>\n",
       "      <td>Reeleito em outubro, o governador tucano Geral...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seis obstáculos e desafios do segundo mandato ...</td>\n",
       "      <td>1. Rearranjo das contas A nova equipe econôm...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Veja os desafios dos governadores que assumem ...</td>\n",
       "      <td>No Acre, governador reeleito quer erradicar an...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT impulsiona cerimônia de posse da Dilma nas ...</td>\n",
       "      <td>Os perfis da presidente Dilma Rousseff, nas re...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titulo  \\\n",
       "0     PT espera 30 mil pessoas em festa na Esplanada   \n",
       "1             Alckmin toma posse de olho no Planalto   \n",
       "2  Seis obstáculos e desafios do segundo mandato ...   \n",
       "3  Veja os desafios dos governadores que assumem ...   \n",
       "4  PT impulsiona cerimônia de posse da Dilma nas ...   \n",
       "\n",
       "                                            conteudo  idNoticia  \n",
       "0  BRASÍLIA - Após o desgaste provocado com o lan...          1  \n",
       "1  Reeleito em outubro, o governador tucano Geral...          2  \n",
       "2    1. Rearranjo das contas A nova equipe econôm...          3  \n",
       "3  No Acre, governador reeleito quer erradicar an...          4  \n",
       "4  Os perfis da presidente Dilma Rousseff, nas re...          5  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_antes = pd.read_csv(\"C:\\\\Users\\\\joao_\\\\Downloads\\\\noticias_estadao.csv\")\n",
    "#data_depois = pd.read_csv(\"C:\\\\Users\\\\joao_\\\\Downloads\\\\noticias_estadao (1).csv\") Novo\n",
    "data_antes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para receber os asserts do mesmo jeito que foi proposta no canvas, vamos definir uma função para receber e retornar as buscas booleanas para AND e para OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(pesquisa):\n",
    "    \n",
    "    pesquisa_split = nltk.word_tokenize(pesquisa.lower())\n",
    "    \n",
    "    palavra1 =   pesquisa_split[0]\n",
    "    operator =   pesquisa_split[1]\n",
    "    palavra2 =   pesquisa_split[2]\n",
    "    \n",
    "    if(operator == 'or'):\n",
    "        return buscar_or(palavra1,palavra2)\n",
    "    elif(operator == 'and'):\n",
    "        return buscar_and(palavra1,palavra2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para pesquisar pelas palavras presentes no data frame vamos usar dois laços. No primeiro, juntamos o título de cada documento com o conteúdo. Depois disso fazemos um split e, no segundo laço, vamos pesquisar se a palavra que queremos está dentro daquela nova string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#funcao para buscar as palavras desejadas\n",
    "id_news = dict()  \n",
    "def busca_termo(palavra_pesquisada):\n",
    "    if(palavra_pesquisada in id_news):\n",
    "        return id_news[palavra_pesquisada]\n",
    "    else:\n",
    "        for x in range(data_antes.shape[0]):             #fazer disso uma funcao  usar -> df.shape[0]  \n",
    "            titulo = data_antes.loc[x,'titulo']         #pego o titulo df.loc -> provavelmente no lab será df.ix\n",
    "            conteudo = data_antes.loc[x,'conteudo']      #pego o conteudo\n",
    "            newWorld = titulo +  \" \" +  conteudo      #concateno os dois separado por espaço\n",
    "            newNova = nltk.word_tokenize(newWorld.lower())   #faço split usando nltk botando tudo para lower case\n",
    "            for y in range(len(newNova)):               #faço outro for para percorrer esse novo split procurando a palavra que eu quero\n",
    "                if(newNova[y] == palavra_pesquisada):  \n",
    "                    if(palavra_pesquisada in id_news):\n",
    "                        id_news[palavra_pesquisada].append(data_antes.loc[x,'idNoticia'])              #posso usar o x do primeiro for por que é o mesmo número do ID\n",
    "                        break;                        #parar para que eu não coloque mais do mesmo indice, caso apareça mais de uma vez\n",
    "                    else:\n",
    "                        id_news[palavra_pesquisada] = [data_antes.loc[x,'idNoticia']]\n",
    "                        break;    \n",
    "                    \n",
    "        return id_news[palavra_pesquisada]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o algoritmo AND, vamos ultilizar do raciocínio do pseudocódigo visto em sala.\n",
    "\n",
    "Nesse algoritmo, queremos retornar apenas os documentos em que as duas palavras estão contidas. Para isso, recebemos duas palavras, procuramos por ela e percorremos cada uma dela até alguma acabar, não sendo mais possível ter documentos iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#local onde vamos fazer o AND\n",
    "\n",
    "\n",
    "def buscar_and(palavra1,palavra2):\n",
    "    \n",
    "    iterator1 = 0\n",
    "    iterator2 = 0\n",
    "    \n",
    "    and_answer = []\n",
    "    \n",
    "    first_and = busca_termo(palavra1)\n",
    "    second_and = busca_termo(palavra2)\n",
    "    \n",
    "    while(iterator1 < len(first_and) and iterator2 < len(second_and)):\n",
    "      if(first_and[iterator1] == second_and[iterator2]):\n",
    "          and_answer.append(first_and[iterator1])\n",
    "          iterator1 +=1\n",
    "          iterator2 +=1\n",
    "      elif(second_and[iterator2] > first_and[iterator1]):\n",
    "          iterator1 +=1\n",
    "      else:\n",
    "          iterator2 += 1\n",
    "    return and_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o algorimo OR, vamos ultilizar a mesma idéia de um merge. Iremos fazer isso em 3 laço.\n",
    "\n",
    "No primeiro laço, percorremos a lista da mesma maneira que percorremos no AND, porém, adicionamos todas as vezes que algum documento for encontrado. Acabado esse laço, não temos a certeza qual das duas listas foi totalmente percorrida. Sendo assim, fazemos mais dois laços que verificam se a lista foi toda percorrida e, se não foi, faz append do resto da sua lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#local onde vamos fazer o OR\n",
    "\n",
    "def buscar_or(palavra1,palavra2):\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    or_answer = []\n",
    "    \n",
    "    first = busca_termo(palavra1)\n",
    "    second = busca_termo(palavra2)\n",
    " \n",
    "    while(i < len(first) and j < len(second)):\n",
    "        if(first[i] < second[j]):\n",
    "            or_answer.append(first[i])\n",
    "            i+= 1\n",
    "        elif(first[i] > second[j]):\n",
    "            or_answer.append(second[j])\n",
    "            j+=1\n",
    "        else:\n",
    "            or_answer.append(second[j])\n",
    "            j+=1\n",
    "            i+=1\n",
    "    while(i < len(first)):\n",
    "        or_answer.append(first[i])\n",
    "        i+=1\n",
    "    while(j < len(second)):\n",
    "        or_answer.append(second[j])\n",
    "        j+=1\n",
    "      \n",
    "    return or_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Para o assert abaixo, tive um pequeno problema. Se eu tivesse usado os dados novos, o tamanho do array  'corruptos' seria 54, enquanto nos dados antigos o tamanho é 53. Por essa diferença, o assert seria 163 e não 164, como descrito no canvas.\n",
    "   Como já tinha feito todo o código, optei por deixar da mesma maneira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Testes<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>AND e OR para debate e presidencial<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(search(\"debate AND presidencial\")) == 201\n",
    "assert len(search(\"debate OR presidencial\")) == 1770"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>AND e OR para presidenciáveis e corruptos<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8bab9a9d63cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"presidenciáveis AND corruptos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"presidenciáveis or corruptos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m163\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'search' is not defined"
     ]
    }
   ],
   "source": [
    "assert len(search(\"presidenciáveis AND corruptos\")) == 0\n",
    "assert len(search(\"presidenciáveis or corruptos\")) == 163"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>AND e OR para Belo e Horizonte<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(search(\"Belo AND Horizonte\")) == 242\n",
    "assert len(search(\"Belo OR Horizonte\")) == 331"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
