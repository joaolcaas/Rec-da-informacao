{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix and Vocabulary Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/joao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/joao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"../Lab3/data/estadao_noticias_eleicao.csv\",encoding=\"utf-8\")\n",
    "news = news.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = news.titulo + \" \" + news.subTitulo + \" \" + news.conteudo\n",
    "content = content.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens_lists = content.apply(lambda text: tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ = stopwords.words('portuguese')\n",
    "filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming list of lists into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for tokens_list in filtered_tokens for token in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, vocab = co_occurrence_matrix(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_words(text):\n",
    "    cont = 0\n",
    "    docs = []\n",
    "    for i, j, k in zip(matrix.row, matrix.col, matrix.data):\n",
    "        if(cont == 3):\n",
    "            break\n",
    "        if(vocab[text] == i):\n",
    "            cont = cont + 1\n",
    "            docs.append(((list(vocab.keys())[list(vocab.values()).index(j)])))\n",
    "                   \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_news = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_term(palavra_pesquisada):\n",
    "    if(palavra_pesquisada in id_news):\n",
    "        return id_news[palavra_pesquisada]\n",
    "    else:\n",
    "        for x in range(news.shape[0]):             #fazer disso uma funcao  usar -> df.shape[0]  \n",
    "            titulo = news.loc[x,'titulo']         #pego o titulo df.loc -> provavelmente no lab será df.ix\n",
    "            conteudo = news.loc[x,'conteudo']  #pego o conteudo\n",
    "            sub_titulo = news.loc[x,'subTitulo']\n",
    "            newWorld = titulo +  \" \" +  conteudo + \" \" + sub_titulo      #concateno os tres separado por espaço\n",
    "            newNova = nltk.word_tokenize(newWorld.lower())   #faço split usando nltk botando tudo para lower case\n",
    "            for y in range(len(newNova)):               #faço outro for para percorrer esse novo split procurando a palavra que eu quero\n",
    "                if(newNova[y] == palavra_pesquisada):  \n",
    "                    if(palavra_pesquisada in id_news):\n",
    "                        id_news[palavra_pesquisada].append(news.loc[x,'idNoticia'])              #posso usar o x do primeiro for por que é o mesmo número do ID\n",
    "                        break;                        #parar para que eu não coloque mais do mesmo indice, caso apareça mais de uma vez\n",
    "                    else:\n",
    "                        id_news[palavra_pesquisada] = [news.loc[x,'idNoticia']]\n",
    "                        break;    \n",
    "                    \n",
    "        return id_news[palavra_pesquisada]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_tops(term):\n",
    "    tops = top3_words(term)\n",
    "    tops.append(term)\n",
    "    result = set()\n",
    "    for i in tops:\n",
    "        print(i)\n",
    "        aux = set(search_term(i))\n",
    "        result = result.union(aux)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Análise do Algoritmo</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em relação a precisão e recall, teremos um trade-off quando compararmos os resultados. Para essa análise, vamos usar os resultados da pesquisa 'lula'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silva\n",
      "dilma\n",
      "disse\n",
      "lula\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6402"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_for_tops('lula'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Vemos que, quando pesquisamos a pesquisa expandida(nesse caso teremos as palavras: SILVA,DILMA,DISSE) o número de documentos retornados vai ser muito maior, ou seja, o recall dessa pesquisa será muito maior do que a pesquisa só de LULA, deixando sua precisão baixa. Porém, temos uma coisa que conta ao favor dessa consulta expandida. Pessoas que pesquisam por LULA podem tender a pesquisar por DILMA também, ou seja, o retorno desses documentos pode ser o mais esperado pelo usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_term('lula'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     Já quando pesquisamos apenas por LULA, vamos o trade-off acontecendo. A precisão será maior, dado que o número de documentos retornados será muito menor, afetando também o recall, sendo menor nesse segundo caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consult Bigram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultable_matrix = matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def consult_frequency(w1, w2):\n",
    "    return(consultable_matrix[vocab[w1],vocab[w2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'poucos'\n",
    "w2 = 'recursos'\n",
    "consult_frequency(w1, w2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
